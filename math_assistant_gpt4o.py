import json
import random
import openai
import os

# è¨­å®š OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "Your API Key")  # âš ï¸ ä½ å¯ä»¥ç›´æ¥åœ¨é€™è£¡å¡«å…¥ API Key
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# è®€å–æ¨™æº– JSON æ ¼å¼çš„ Ape210K é¡Œåº«
with open("ape210k_test.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# éš¨æ©Ÿé¸æ“‡ä¸€é“é¡Œç›®
def get_random_question(data):
    question = random.choice(data)
    return {
        "question": question["original_text"],
        "answer": question["ans"],
        "equation": question["equation"]
    }

# ä½¿ç”¨ OpenAI GPT-4o-mini ä¾†è™•ç†å°è©±
def chat_with_gpt(messages):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        stream=True  # âœ… å•Ÿç”¨æµå¼è¼¸å‡º
    )

    print("\nğŸ“– GPT-4o-mini å›ç­”ï¼š", end="", flush=True)
    for chunk in response:
        if chunk.choices and chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print("\n")  # âœ… ç¢ºä¿è¼¸å‡ºæ›è¡Œ

# ä¸»ç¨‹å¼
if __name__ == "__main__":
    print("\nğŸ“ æ­¡è¿ä¾†åˆ°å°å­¸ç”Ÿæ•¸å­¸è¼”åŠ©ç³»çµ±ï¼")
    print("ğŸ”¹ ä½ å¯ä»¥è¼¸å…¥ä½ çš„ç­”æ¡ˆï¼ŒGPT-4o-mini æœƒå¹«ä½ æª¢æŸ¥æ­£ç¢ºæ€§ã€‚")
    print("ğŸ”¹ å¦‚æœæœ‰å…¶ä»–å•é¡Œï¼Œä¹Ÿå¯ä»¥ç¹¼çºŒæå•ï¼")
    print("ğŸ”¹ æŒ‰ `Ctrl+C` æˆ– `Ctrl+D` é€€å‡ºç¨‹å¼ã€‚\n")

    try:
        while True:  # âœ… å…è¨±å¤šè¼ªå°è©±
            sample_question = get_random_question(data)
            print("\nğŸ“Œ é¡Œç›®:", sample_question["question"])

            # åˆå§‹åŒ–å°è©±ä¸Šä¸‹æ–‡
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°å­¸æ•¸å­¸è€å¸«ï¼Œè² è²¬æ‰¹æ”¹å­¸ç”Ÿçš„ç­”æ¡ˆä¸¦æä¾›è§£é‡‹ã€‚"},
                {"role": "user", "content": f"é€™æ˜¯ä¸€é“å°å­¸æ•¸å­¸é¡Œç›®ï¼š{sample_question['question']}"},
            ]

            # è®“ä½¿ç”¨è€…è¼¸å…¥ç­”æ¡ˆ
            user_answer = input("âœï¸ è«‹è¼¸å…¥ä½ çš„ç­”æ¡ˆï¼š ")

            # åŠ å…¥å­¸ç”Ÿçš„å›ç­”
            messages.append({"role": "user", "content": f"æˆ‘çš„ç­”æ¡ˆæ˜¯ï¼š{user_answer}"})

            # è®“ GPT-4o-mini å¹«åŠ©åˆ¤æ–·ç­”æ¡ˆæ˜¯å¦æ­£ç¢ºï¼ˆæµå¼è¼¸å‡ºï¼‰
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages + [
                    {"role": "user", "content": f"é€™é“é¡Œçš„æ­£ç¢ºç­”æ¡ˆæ˜¯ {sample_question['answer']}ã€‚è«‹åˆ¤æ–·æˆ‘çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¢ºï¼Œä¸¦æä¾›è©³ç´°è§£é‡‹ã€‚"}
                ],
                temperature=0.2,
                stream=True
            )

            print("\nğŸ“– GPT-4o-mini åˆ¤æ–·çµæœï¼š", end="", flush=True)
            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    print(chunk.choices[0].delta.content, end="", flush=True)
            print("\n")

            # å°‡ GPT-4o-mini çš„å›æ‡‰åŠ å…¥å°è©±ä¸Šä¸‹æ–‡
            messages.append({"role": "assistant", "content": "GPT-4o-mini åˆ¤æ–·çµæœï¼š"})

            # å…è¨±ä½¿ç”¨è€…ç¹¼çºŒæå•ï¼Œä¸¦ç¶­æŒä¸Šä¸‹æ–‡
            while True:
                follow_up = input("\nğŸ’¡ ä½ é‚„æœ‰å…¶ä»–å•é¡Œå—ï¼Ÿ(è¼¸å…¥å•é¡Œæˆ–æŒ‰ Enter è®“æˆ‘å‡ºæ–°é¡Œç›®)ï¼š ").strip()
                if follow_up == "":
                    break  # è®“ç³»çµ±å‡ºä¸‹ä¸€é“é¡Œç›®
                else:
                    messages.append({"role": "user", "content": follow_up})  # âœ… ä¿ç•™å°è©±ä¸Šä¸‹æ–‡
                    chat_with_gpt(messages)  # âœ… ä½¿ç”¨ä¸Šä¸‹æ–‡å›ç­”

    except (KeyboardInterrupt, EOFError):
        print("\nğŸ“š æ„Ÿè¬ä½¿ç”¨å­¸ç¿’ç³»çµ±ï¼Œå†è¦‹ï¼ğŸ‘‹")
